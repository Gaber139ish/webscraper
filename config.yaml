start_urls:
  - "https://news.ycombinator.com"
  - "https://arxiv.org"
max_depth: 2
concurrency: 2
user_agent: "Mozilla/5.0 (X11; Linux x86_64) CoineyScraper/1.0"
user_agents: []  # optional rotation list; if empty, uses user_agent above
proxies:
  playwright: []  # e.g., ["http://user:pass@host:port", "socks5://host:port"]
  httpx: null     # e.g., {"http": "http://host:port", "https": "http://host:port"}
output:
  jsonl: "./exports/dataset.jsonl"
  sqlite: "./exports/dataset.db"
crawl:
  follow_external: false
  respect_robots: true
  wait_after_load: 1.0
  intercept_api: true
rate_limit:
  delay_seconds: 0.5
  per_domain_delays: {}
github:
  token: ""                # optional, recommended for higher rate limits
  query: "language:python machine learning"
  per_page: 10
  pages: 2
  max_files_per_repo: 200
  extensions: [".py", ".js", ".cpp", ".c", ".java", ".rs"]
  max_file_size: 200000   # bytes
  concurrency: 8
  output_dir: "exports/github_code"
datasets:
  output_dir: "exports/datasets"
  web_dataset_name: "web_text"
  code_dataset_name: "code_text"
  val_ratio: 0.05
  min_text_length: 200
